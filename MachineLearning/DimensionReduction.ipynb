{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitdataconda5467872f862141fb83a5467f0628293e",
   "display_name": "Python 3.8.1 64-bit ('Data': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ML Classifier (Support Vector Machine & Logistic Regression)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set pyplot style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Dimensionality Reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset from datasets directory\n",
    "ansur = pd.read_csv('~/DevSpace/Data-Snippets/MachineLearning/datasets/ansur.csv')\n",
    "ansur.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot perfect correlation in data\n",
    "cmap = sns.diverging_palette(h_neg=10, h_pos=240, as_cmap=True)\n",
    "sns.heatmap(ansur.corr(), center=0, cmap=cmap, linewidths=1, annot=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix for Ansur Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force removal of hightly correlated features\n",
    "abs_corr_matrix = ansur.corr().abs()\n",
    "\n",
    "# Upper triagule of corr matrix to false\n",
    "mask = np.triu(np.ones_like(abs_corr_matrix, dtype=bool))\n",
    "tri_df = abs_corr_matrix.mask(mask)\n",
    "\n",
    "# Filter highly correlated dimensions\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] >  0.95)]\n",
    "\n",
    "# Drop highly correlated dimensions\n",
    "reduced_df = ansur.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check visualization\n",
    "sns.pairplot(reduced_df, hue='Gender', diag_kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High dimensional data import\n",
    "body_dims = pd.read_csv('~/DevSpace/Data-Snippets/MachineLearning/datasets/body_measurements.csv')\n",
    "body_dims.drop('ID', axis=1, inplace=True)\n",
    "print(f'Number of dimensions (cols): {len(body_dims.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate TSNE Model\n",
    "tsne_model = TSNE(learning_rate=50)\n",
    "\n",
    "# Fit and transform numeric data from 4th column\n",
    "tsne_features = tsne_model.fit_transform(body_dims.iloc[:, 4:])\n",
    "\n",
    "# Add components to df\n",
    "body_dims['x'] = tsne_features[:, 0]\n",
    "body_dims['y'] = tsne_features[:, 1]\n",
    "\n",
    "# Plot transformed data\n",
    "sns.scatterplot(x='x', y='y', hue='Gender', data=body_dims)\n",
    "plt.xlabel('X Dimension')\n",
    "plt.ylabel('Y Dimension')\n",
    "plt.title('t-SNE of Body Measurements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict 'Gender' based on all body measurements\n",
    "y = body_dims['Gender']\n",
    "X = body_dims.drop(['Branch', 'Component', 'Gender', 'x', 'y'], axis=1)\n",
    "\n",
    "# Split train, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=12)\n",
    "\n",
    "# Instanciate model and fit model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Measure accuracy\n",
    "acc_train = accuracy_score(y_train, svm.predict(X_train))\n",
    "acc_test = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# Measure overfitting abs(train - test / test)\n",
    "print(f'{acc_train = }')\n",
    "print(f'{acc_test = }')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Gender based on 'neckcircumferencebase' feature \n",
    "y = body_dims['Gender']\n",
    "X = body_dims[['neckcircumferencebase']]\n",
    "\n",
    "# Split train, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=12)\n",
    "\n",
    "# Instanciate model and fit model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Measure accuracy\n",
    "acc_train = accuracy_score(y_train, svm.predict(X_train))\n",
    "acc_test = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# Measure overfitting abs(train - test / test)\n",
    "print(f'{acc_train = }')\n",
    "print(f'{acc_test = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study the distribution of the variances from all dimensions from body_dims\n",
    "\n",
    "# Normalize columns for better visualization\n",
    "numeric_dims = body_dims.iloc[:, 3:-2] / body_dims.iloc[:, 3:-2].mean()\n",
    "\n",
    "# Calculate variances, median and mean\n",
    "vars = numeric_dims.std() ** 2\n",
    "median = round(vars.quantile(), 5)\n",
    "mean = round(vars.mean(), 5)\n",
    "\n",
    "# Plot variance distribution and annotate\n",
    "sns.boxplot(y=vars.values)\n",
    "plt.annotate(f'Median variance: {median}', (-0.45, 0.022))\n",
    "plt.annotate(f'Mean variance: {mean}', (-0.45, 0.0195))\n",
    "\n",
    "plt.xlabel('Variances')\n",
    "plt.ylabel('Normalized Variance')\n",
    "plt.title('Normalized variance distribution of dimensions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality with a variance threshold (median variance)\n",
    "variance_selection = VarianceThreshold(threshold=0.00482)\n",
    "\n",
    "# Fit variance selector\n",
    "variance_selection.fit(numeric_dims)\n",
    "\n",
    "# Get variance mask\n",
    "mask = variance_selection.get_support()\n",
    "\n",
    "# Reduced body_dims\n",
    "reduced_body = numeric_dims.loc[:, mask]\n",
    "\n",
    "# New number of dimensions\n",
    "print(f'Old dimensions: {len(body_dims.columns)}')\n",
    "print(f'New dimensions: {len(reduced_body.columns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Gender based on reduced dataset\n",
    "y = body_dims['Gender']\n",
    "X = reduced_body\n",
    "\n",
    "# Split train, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=12)\n",
    "\n",
    "# Instanciate model and fit model\n",
    "svm = SVC(C=0.1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Measure accuracy\n",
    "acc_train = accuracy_score(y_train, svm.predict(X_train))\n",
    "acc_test = accuracy_score(y_test, svm.predict(X_test))\n",
    "\n",
    "# Measure overfitting abs(train - test / test)\n",
    "print(f'{acc_train = }')\n",
    "print(f'{acc_test = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Gender with a classifier less prone to overfit (simpler model)\n",
    "log_reg = LogisticRegression(solver='newton-cg', C=0.1)\n",
    "\n",
    "# Fit Model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Measure Accuracy\n",
    "acc_train = accuracy_score(y_train, log_reg.predict(X_train))\n",
    "acc_test = accuracy_score(y_test, log_reg.predict(X_test))\n",
    "\n",
    "# Measure overfitting abs(train - test / test)\n",
    "print(f'{acc_train = }')\n",
    "print(f'{acc_test = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of dimensions and coefficients\n",
    "lr_coefs = dict(zip(reduced_body.columns, np.abs(log_reg.coef_[0])))\n",
    "\n",
    "# Sort by most important coefficients\n",
    "lr_coefs = sorted(lr_coefs.items(), key=lambda x: x[1], reverse=True)\n",
    "pd.Series(dict(lr_coefs[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Elimination\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=1)\n",
    "\n",
    "# Fit RFE with model\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Rank features\n",
    "feature_ranking = dict(zip(X.columns, rfe.ranking_))\n",
    "\n",
    "# Sort ranking from less to most important\n",
    "sorted_features = dict(sorted(feature_ranking.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "# Order DataFrame\n",
    "ranking_df = reduced_body[sorted_features.keys()]\n",
    "\n",
    "# Declare X, y\n",
    "X, y = ranking_df, body_dims['Gender']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save accuracy scores\n",
    "accuracy = []\n",
    "\n",
    "# Iterate over all models\n",
    "for i in range(len(sorted_features)):\n",
    "\n",
    "    # Train Test Split with ordered features\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, i:], y, train_size=0.7, random_state=12)\n",
    "\n",
    "    # Train model with those features\n",
    "    log_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Measure accuracy\n",
    "    train_acc = accuracy_score(y_train, log_reg.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, log_reg.predict(X_test))\n",
    "    accuracy.append([len(X_train.columns), train_acc, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract accuracy data from experiment\n",
    "accuracy = np.array(accuracy)\n",
    "features, train, test = np.split(accuracy, 3, axis=1)\n",
    "features = features.flatten().astype('int')\n",
    "\n",
    "# Plot lines of training adn testing accuracy\n",
    "plt.plot(train, label='Train Score')\n",
    "plt.plot(test, label='Test Score')\n",
    "plt.xticks(features[::5], features[::-5])\n",
    "\n",
    "# Annotate figure\n",
    "plt.title('Train & Test scores by number of features')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Number of Features')\n",
    "\n",
    "# Figure style and legend\n",
    "plt.xlim(0, 45)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}